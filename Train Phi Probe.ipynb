{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67cc4a-347b-45cd-bdb1-c3bc641c35ed",
   "metadata": {},
   "source": [
    "## Set up dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f917e4-5b5b-4e0e-a1bb-aa7df0ad62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post304)\n",
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchinfo tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967f09f2-a99a-45e1-b6f2-ff8eb3fd596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset, Dataset, IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f279a0-f815-4076-98c0-932e9d761a3e",
   "metadata": {},
   "source": [
    "## Download the Dolma v1.6_sample dataset (~16GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a258afee-5fde-48d5-b5d8-11ea42721528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('allenai/dolma', name='v1_6-sample', trust_remote_code=True, streaming=True, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507ae68-83fe-4afa-8d93-6cf223a8a42c",
   "metadata": {},
   "source": [
    "## Load phi-2 and set up a method that gets the middle layer's activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568eb6c5-8303-4d55-818e-b2bbc481e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-07-25 17:36:31.821871: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 17:36:31.859638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6f05bb0ee24f5381232d0aaf8eac7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "\n",
    "phi = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=torch.float16, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7631986b-09ca-4a35-9cf6-917b111c613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings about tokenising long passages. \n",
    "# We're going to handle splitting the text ourselves.\n",
    "import sys\n",
    "tokenizer.model_max_length = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303c6350-0a75-4628-a72f-6a33eb9ca754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text, return_tensors=\"pt\", return_attention_mask=False)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951eb3c6-fe26-4502-aae6-8045718229ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_activations(tokens):\n",
    "    \"\"\"\n",
    "    Takes a tensor of shape e.g. (B, T) containing a batch of token strings,\n",
    "    and outputs a tensor of shape (B, T, 2560) containing the activations\n",
    "    of the middle layer (hidden layer 15) at each token.\n",
    "    \"\"\"\n",
    "    out = phi(tokens, output_hidden_states=True, return_dict=True)\n",
    "    hidden_states = out.hidden_states\n",
    "    middle_layer = hidden_states[16]\n",
    "    return middle_layer.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2666b9b6-7dcd-4aac-9cee-9d7d860e4d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_token_blocks(text, block_size):\n",
    "    \"\"\"\n",
    "    Given a text, tokenizes it and returns a tensor of shape \n",
    "    (N, BS) containing the text as a series of blocks of \n",
    "    tokens of size BS.\n",
    "    N is the number of blocks contained within the text.   \n",
    "    \"\"\"    \n",
    "    block_size = 100\n",
    "    tokens = tokenize(text).view(-1)\n",
    "    truncated_length = (len(tokens) // block_size) * block_size\n",
    "    tokens = tokens[:truncated_length]\n",
    "    block_tensor = tokens.view(-1, block_size)\n",
    "    blocks = torch.split(block_tensor, 1, dim=0)    \n",
    "    return [b.view(-1) for b in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89575e7-8714-4819-af4d-606cd03a48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_blocks(split, block_size=100):    \n",
    "    for i, example in enumerate(data):\n",
    "        is_test_example = i % 10 == 0\n",
    "        if split == 'train' and is_test_example or split != 'train' and not is_test_example:\n",
    "            continue\n",
    "        for block in get_token_blocks(example['text'], block_size=block_size):                        \n",
    "            yield block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24182c0b-6359-4856-85f8-8867d67c30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterable(iterable, batch_size):\n",
    "    current_batch = []\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == batch_size:\n",
    "            yield current_batch\n",
    "            current_batch = []\n",
    "\n",
    "\n",
    "def all_activations(split, block_size=100, minibatch_size=5, start_block=0, parallelism=10, workahead_cache_size=50):\n",
    "    \"\"\"\n",
    "    Generator yielding minibatches of training examples.\n",
    "    Each example is returned as a tuple (tokens, activations).\n",
    "     - tokens is a tensor of dimention (MB, BS) where MB \n",
    "       is the specified minibatch size, and BS is the block size.\n",
    "     - activations is a tensor of dimension (MB, BS, 2560)\n",
    "    \"\"\"    \n",
    "    global phi\n",
    "    assert workahead_cache_size % parallelism == 0\n",
    "    assert workahead_cache_size % minibatch_size == 0\n",
    "    assert parallelism % minibatch_size == 0\n",
    "    blocks = islice(all_blocks(split, block_size=block_size), start_block, None)\n",
    "    for block_megabatch in batch_iterable(blocks, workahead_cache_size):  \n",
    "        phi = phi.to(\"cuda\")\n",
    "        minibatches = []        \n",
    "        for inputs in torch.stack(block_megabatch).split(parallelism):            \n",
    "            activations = get_activations(inputs)      \n",
    "            minibatch_inputs = inputs.split(minibatch_size)\n",
    "            minibatch_activations = activations.split(minibatch_size)\n",
    "            minibatches.extend(zip(minibatch_inputs, minibatch_activations))\n",
    "        phi = phi.to(\"cpu\")\n",
    "        \n",
    "        for minibatch_input, minibatch_activation in minibatches:\n",
    "            yield minibatch_input, minibatch_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499c76c-2591-453a-a9bc-e8b89c2d65ea",
   "metadata": {},
   "source": [
    "## Now define our autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f93598-167b-449e-9573-90e038d86cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, activation_dimension=2560, inner_dimension=100_000):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(activation_dimension, inner_dimension),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Linear(inner_dimension, activation_dimension)\n",
    "\n",
    "    def forward(self, activations):\n",
    "        encoded = self.encoder(activations)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded  # Return encoded too, as it's used in the loss fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "871ec152-cd46-43f4-b4f2-a7e0074439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('sae.pt').exists():\n",
    "    sae = torch.load('sae.pt').to(device)\n",
    "    is_trained = True\n",
    "else:\n",
    "    sae = SparseAutoencoder()\n",
    "    is_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395fa780-5d92-4742-8978-9fcb9d77430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def calculate_loss(sae_model, prediction, target, feature_activations, lamb=5):\n",
    "    weight_norms = torch.norm(sae_model.decoder.weight, dim=0, p=2).view(-1)\n",
    "    feature_sizes = torch.abs(feature_activations)\n",
    "    sparsity_loss = lamb * torch.sum(weight_norms * feature_sizes)\n",
    "\n",
    "    prediction_loss = F.mse_loss(prediction, target, reduction='sum')\n",
    "\n",
    "    total_loss = prediction_loss + sparsity_loss\n",
    "    \n",
    "    return total_loss, prediction_loss, sparsity_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d944680f-4a0f-470b-b2a3-798cc0f3e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15655829504 7822376960 7616183296 206193664\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t, r, a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24c23c-418a-4b12-acdf-bb8117887a64",
   "metadata": {},
   "source": [
    "## Train our autoencoder on 1M tokens' worth of activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1048f3ee-14c2-490b-b308-348f92ca2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 25000; Loss: 20933.04; Sparsity-specific loss: 10754.98:   2%|▏         | 49/2000 [00:57<38:03,  1.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 25000 tokens\n",
      "\t - Training data: loss is 20933.04; sparsity loss is 10754.98\n",
      "\t - Eval data: loss is 10815.54; sparsity loss is 7070.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 50000; Loss: 15219.29; Sparsity-specific loss: 8368.90:   5%|▍         | 99/2000 [01:57<37:27,  1.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 50000 tokens\n",
      "\t - Training data: loss is 15219.29; sparsity loss is 8368.90\n",
      "\t - Eval data: loss is 8329.01; sparsity loss is 4630.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 75000; Loss: 8548.77; Sparsity-specific loss: 5178.10:   7%|▋         | 149/2000 [02:48<34:55,  1.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 75000 tokens\n",
      "\t - Training data: loss is 8548.77; sparsity loss is 5178.10\n",
      "\t - Eval data: loss is 7096.80; sparsity loss is 3716.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 100000; Loss: 6943.79; Sparsity-specific loss: 3883.54:  10%|▉         | 199/2000 [03:39<33:09,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 100000 tokens\n",
      "\t - Training data: loss is 6943.79; sparsity loss is 3883.54\n",
      "\t - Eval data: loss is 6099.36; sparsity loss is 2952.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 125000; Loss: 5782.35; Sparsity-specific loss: 2989.93:  12%|█▏        | 249/2000 [04:31<31:46,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 125000 tokens\n",
      "\t - Training data: loss is 5782.35; sparsity loss is 2989.93\n",
      "\t - Eval data: loss is 5183.12; sparsity loss is 2226.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 150000; Loss: 4877.06; Sparsity-specific loss: 2269.96:  15%|█▍        | 299/2000 [05:22<30:33,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 150000 tokens\n",
      "\t - Training data: loss is 4877.06; sparsity loss is 2269.96\n",
      "\t - Eval data: loss is 4446.63; sparsity loss is 1690.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 175000; Loss: 4229.23; Sparsity-specific loss: 1713.22:  17%|█▋        | 349/2000 [06:17<29:46,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 175000 tokens\n",
      "\t - Training data: loss is 4229.23; sparsity loss is 1713.22\n",
      "\t - Eval data: loss is 3987.32; sparsity loss is 1196.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 200000; Loss: 3912.51; Sparsity-specific loss: 1337.31:  20%|█▉        | 399/2000 [07:09<28:42,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 200000 tokens\n",
      "\t - Training data: loss is 3912.51; sparsity loss is 1337.31\n",
      "\t - Eval data: loss is 3676.87; sparsity loss is 864.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 225000; Loss: 3726.95; Sparsity-specific loss: 1054.77:  22%|██▏       | 449/2000 [08:00<27:40,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 225000 tokens\n",
      "\t - Training data: loss is 3726.95; sparsity loss is 1054.77\n",
      "\t - Eval data: loss is 3650.05; sparsity loss is 714.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 250000; Loss: 3474.29; Sparsity-specific loss: 817.90:  25%|██▍       | 499/2000 [08:52<26:40,  1.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 250000 tokens\n",
      "\t - Training data: loss is 3474.29; sparsity loss is 817.90\n",
      "\t - Eval data: loss is 3384.58; sparsity loss is 667.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 275000; Loss: 3225.81; Sparsity-specific loss: 679.14:  27%|██▋       | 549/2000 [09:44<25:43,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 275000 tokens\n",
      "\t - Training data: loss is 3225.81; sparsity loss is 679.14\n",
      "\t - Eval data: loss is 3298.96; sparsity loss is 618.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 300000; Loss: 2892.85; Sparsity-specific loss: 610.35:  30%|██▉       | 599/2000 [10:39<24:56,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 300000 tokens\n",
      "\t - Training data: loss is 2892.85; sparsity loss is 610.35\n",
      "\t - Eval data: loss is 3112.89; sparsity loss is 562.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 325000; Loss: 2586.66; Sparsity-specific loss: 590.88:  32%|███▏      | 649/2000 [11:30<23:57,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 325000 tokens\n",
      "\t - Training data: loss is 2586.66; sparsity loss is 590.88\n",
      "\t - Eval data: loss is 3102.28; sparsity loss is 598.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 350000; Loss: 2404.09; Sparsity-specific loss: 592.08:  35%|███▍      | 699/2000 [12:20<22:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 350000 tokens\n",
      "\t - Training data: loss is 2404.09; sparsity loss is 592.08\n",
      "\t - Eval data: loss is 3109.60; sparsity loss is 611.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 375000; Loss: 2285.37; Sparsity-specific loss: 595.19:  37%|███▋      | 749/2000 [13:11<22:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 375000 tokens\n",
      "\t - Training data: loss is 2285.37; sparsity loss is 595.19\n",
      "\t - Eval data: loss is 3448.28; sparsity loss is 664.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 400000; Loss: 2255.17; Sparsity-specific loss: 598.25:  40%|███▉      | 799/2000 [14:01<21:05,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 400000 tokens\n",
      "\t - Training data: loss is 2255.17; sparsity loss is 598.25\n",
      "\t - Eval data: loss is 3338.53; sparsity loss is 645.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 425000; Loss: 2247.91; Sparsity-specific loss: 601.14:  42%|████▏     | 849/2000 [14:56<20:15,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 425000 tokens\n",
      "\t - Training data: loss is 2247.91; sparsity loss is 601.14\n",
      "\t - Eval data: loss is 3409.00; sparsity loss is 665.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 450000; Loss: 2226.60; Sparsity-specific loss: 602.64:  45%|████▍     | 899/2000 [15:47<19:20,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 450000 tokens\n",
      "\t - Training data: loss is 2226.60; sparsity loss is 602.64\n",
      "\t - Eval data: loss is 2986.37; sparsity loss is 594.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 475000; Loss: 2174.69; Sparsity-specific loss: 605.12:  47%|████▋     | 949/2000 [16:37<18:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 475000 tokens\n",
      "\t - Training data: loss is 2174.69; sparsity loss is 605.12\n",
      "\t - Eval data: loss is 2929.66; sparsity loss is 617.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 500000; Loss: 2136.36; Sparsity-specific loss: 610.42:  50%|████▉     | 999/2000 [17:28<17:30,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 500000 tokens\n",
      "\t - Training data: loss is 2136.36; sparsity loss is 610.42\n",
      "\t - Eval data: loss is 2930.72; sparsity loss is 618.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 525000; Loss: 2099.28; Sparsity-specific loss: 611.47:  52%|█████▏    | 1049/2000 [18:18<16:35,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 525000 tokens\n",
      "\t - Training data: loss is 2099.28; sparsity loss is 611.47\n",
      "\t - Eval data: loss is 2910.00; sparsity loss is 616.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 550000; Loss: 2325.50; Sparsity-specific loss: 621.15:  55%|█████▍    | 1099/2000 [19:12<15:45,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 550000 tokens\n",
      "\t - Training data: loss is 2325.50; sparsity loss is 621.15\n",
      "\t - Eval data: loss is 2781.70; sparsity loss is 552.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 575000; Loss: 2607.27; Sparsity-specific loss: 615.67:  57%|█████▋    | 1149/2000 [20:02<14:50,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 575000 tokens\n",
      "\t - Training data: loss is 2607.27; sparsity loss is 615.67\n",
      "\t - Eval data: loss is 2605.43; sparsity loss is 571.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 600000; Loss: 2571.68; Sparsity-specific loss: 604.75:  60%|█████▉    | 1199/2000 [20:53<13:57,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 600000 tokens\n",
      "\t - Training data: loss is 2571.68; sparsity loss is 604.75\n",
      "\t - Eval data: loss is 2694.80; sparsity loss is 610.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 625000; Loss: 2492.02; Sparsity-specific loss: 615.01:  62%|██████▏   | 1249/2000 [21:43<13:03,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 625000 tokens\n",
      "\t - Training data: loss is 2492.02; sparsity loss is 615.01\n",
      "\t - Eval data: loss is 2749.69; sparsity loss is 646.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 650000; Loss: 2482.45; Sparsity-specific loss: 627.44:  65%|██████▍   | 1299/2000 [22:33<12:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 650000 tokens\n",
      "\t - Training data: loss is 2482.45; sparsity loss is 627.44\n",
      "\t - Eval data: loss is 2738.97; sparsity loss is 622.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 675000; Loss: 2511.90; Sparsity-specific loss: 630.11:  67%|██████▋   | 1349/2000 [23:28<11:19,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 675000 tokens\n",
      "\t - Training data: loss is 2511.90; sparsity loss is 630.11\n",
      "\t - Eval data: loss is 2634.61; sparsity loss is 609.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 700000; Loss: 2569.25; Sparsity-specific loss: 632.83:  70%|██████▉   | 1399/2000 [24:19<10:26,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 700000 tokens\n",
      "\t - Training data: loss is 2569.25; sparsity loss is 632.83\n",
      "\t - Eval data: loss is 2618.81; sparsity loss is 606.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 725000; Loss: 2529.63; Sparsity-specific loss: 639.86:  72%|███████▏  | 1449/2000 [25:09<09:34,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 725000 tokens\n",
      "\t - Training data: loss is 2529.63; sparsity loss is 639.86\n",
      "\t - Eval data: loss is 2670.80; sparsity loss is 646.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 750000; Loss: 2399.98; Sparsity-specific loss: 640.15:  75%|███████▍  | 1499/2000 [25:59<08:41,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 750000 tokens\n",
      "\t - Training data: loss is 2399.98; sparsity loss is 640.15\n",
      "\t - Eval data: loss is 2733.29; sparsity loss is 672.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 775000; Loss: 2335.51; Sparsity-specific loss: 645.79:  77%|███████▋  | 1549/2000 [26:50<07:48,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 775000 tokens\n",
      "\t - Training data: loss is 2335.51; sparsity loss is 645.79\n",
      "\t - Eval data: loss is 2685.68; sparsity loss is 672.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 800000; Loss: 2307.24; Sparsity-specific loss: 650.73:  80%|███████▉  | 1599/2000 [27:45<06:57,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 800000 tokens\n",
      "\t - Training data: loss is 2307.24; sparsity loss is 650.73\n",
      "\t - Eval data: loss is 2657.08; sparsity loss is 702.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 825000; Loss: 2358.24; Sparsity-specific loss: 650.78:  82%|████████▏ | 1649/2000 [28:35<06:05,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 825000 tokens\n",
      "\t - Training data: loss is 2358.24; sparsity loss is 650.78\n",
      "\t - Eval data: loss is 2652.35; sparsity loss is 647.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 850000; Loss: 2385.71; Sparsity-specific loss: 646.72:  85%|████████▍ | 1699/2000 [29:25<05:12,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 850000 tokens\n",
      "\t - Training data: loss is 2385.71; sparsity loss is 646.72\n",
      "\t - Eval data: loss is 2613.16; sparsity loss is 663.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 875000; Loss: 2328.33; Sparsity-specific loss: 644.54:  87%|████████▋ | 1749/2000 [30:15<04:20,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 875000 tokens\n",
      "\t - Training data: loss is 2328.33; sparsity loss is 644.54\n",
      "\t - Eval data: loss is 2553.48; sparsity loss is 657.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 900000; Loss: 2284.78; Sparsity-specific loss: 651.81:  90%|████████▉ | 1799/2000 [31:06<03:28,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 900000 tokens\n",
      "\t - Training data: loss is 2284.78; sparsity loss is 651.81\n",
      "\t - Eval data: loss is 2413.09; sparsity loss is 661.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 925000; Loss: 2279.90; Sparsity-specific loss: 656.46:  92%|█████████▏| 1849/2000 [32:01<02:36,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 925000 tokens\n",
      "\t - Training data: loss is 2279.90; sparsity loss is 656.46\n",
      "\t - Eval data: loss is 2469.32; sparsity loss is 649.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 950000; Loss: 2252.06; Sparsity-specific loss: 653.83:  95%|█████████▍| 1899/2000 [32:51<01:44,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 950000 tokens\n",
      "\t - Training data: loss is 2252.06; sparsity loss is 653.83\n",
      "\t - Eval data: loss is 2444.00; sparsity loss is 669.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 975000; Loss: 2205.94; Sparsity-specific loss: 655.70:  97%|█████████▋| 1949/2000 [33:42<00:52,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 975000 tokens\n",
      "\t - Training data: loss is 2205.94; sparsity loss is 655.70\n",
      "\t - Eval data: loss is 2496.29; sparsity loss is 642.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 1000000; Loss: 2247.79; Sparsity-specific loss: 664.02: 100%|█████████▉| 1999/2000 [34:34<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 1000000 tokens\n",
      "\t - Training data: loss is 2247.79; sparsity loss is 664.02\n",
      "\t - Eval data: loss is 2584.46; sparsity loss is 657.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 1000000; Loss: 2247.79; Sparsity-specific loss: 664.02: 100%|██████████| 2000/2000 [34:37<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_eval_loss(sae_model, minibatches, tokens_per_minibatch):\n",
    "    losses = []\n",
    "    sparsities = []\n",
    "    accuracies = []\n",
    "    for tokens, activations in minibatches:\n",
    "        decoded, encoded = sae_model(activations)\n",
    "        loss, accuracy, sparsity = calculate_loss(sae_model, decoded, activations, encoded)\n",
    "        losses.append(loss.item() / tokens_per_minibatch)\n",
    "        accuracies.append(accuracy.item() / tokens_per_minibatch)        \n",
    "        sparsities.append(sparsity.item() / tokens_per_minibatch)        \n",
    "    return sum(losses) / len(losses), sum(accuracies) / len(accuracies), sum(sparsities) / len(sparsities)\n",
    "\n",
    "def train(sae_model, num_tokens=1000000, minibatch_size=5, block_size=100, loss_history=100, adam_beta1=0.9, adam_beta2=0.999, lr=5E-5, eval_tokens=1000, show_eval_token_interval=25000, start_block=0):            \n",
    "    optimizer = torch.optim.AdamW(sae_model.parameters(), lr=lr, betas=(adam_beta1, adam_beta2))\n",
    "    tokens_per_minibatch = minibatch_size * block_size\n",
    "    num_minibatches = num_tokens // tokens_per_minibatch\n",
    "    eval_minibatches = eval_tokens // tokens_per_minibatch\n",
    "    losses = []\n",
    "    sparsities = []\n",
    "    activations_gen = all_activations('train', minibatch_size=minibatch_size, block_size=block_size + start_block)\n",
    "    test_activations_gen = all_activations('test', minibatch_size=minibatch_size, block_size=block_size, start_block=1000+start_block)    \n",
    "    \n",
    "    training_data = islice(activations_gen, num_minibatches)         \n",
    "    show_eval_minibatch_interval = show_eval_token_interval // tokens_per_minibatch\n",
    "\n",
    "    pbar = tqdm(training_data, total=num_minibatches, smoothing=0)\n",
    "    for idx, (tokens, activations) in enumerate(pbar):        \n",
    "        decoded, encoded = sae_model(activations)        \n",
    "        loss, accuracy, sparsity = calculate_loss(sae_model, decoded, activations, encoded)        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        losses.append(loss.item() / tokens_per_minibatch)\n",
    "        sparsities.append(sparsity.item() / tokens_per_minibatch)\n",
    "        if len(losses) > loss_history:\n",
    "            losses = losses[1:]\n",
    "            sparsities = sparsities[1:]\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        avg_sparsity = sum(sparsities) / len(sparsities)\n",
    "        tokens_seen = (idx + 1) * tokens_per_minibatch\n",
    "        pbar.set_description(f'Tokens seen: {tokens_seen}; Loss: {avg_loss:.2f}; Sparsity-specific loss: {avg_sparsity:.2f}')\n",
    "        if (idx + 1) % show_eval_minibatch_interval == 0:\n",
    "            minibatches = islice(test_activations_gen, eval_minibatches)\n",
    "            eval_loss, _, eval_sparsity = get_eval_loss(sae_model, minibatches, tokens_per_minibatch)\n",
    "            print(f'Seen {tokens_seen} tokens')\n",
    "            print(f'\\t - Training data: loss is {avg_loss:.2f}; sparsity loss is {avg_sparsity:.2f}')\n",
    "            print(f'\\t - Eval data: loss is {eval_loss:.2f}; sparsity loss is {eval_sparsity:.2f}')            \n",
    "            torch.save(sae, 'sae.pt')\n",
    "\n",
    "if not is_trained:\n",
    "    train(sae)\n",
    "    is_trained = True\n",
    "    torch.save(sae, 'sae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c3791ea-13e0-410c-a8b3-24605a50ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "PhiForCausalLM                                          --\n",
      "├─PhiModel: 1-1                                         --\n",
      "│    └─Embedding: 2-1                                   131,072,000\n",
      "│    └─Dropout: 2-2                                     --\n",
      "│    └─ModuleList: 2-3                                  --\n",
      "│    │    └─PhiDecoderLayer: 3-1                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-2                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-3                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-4                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-5                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-6                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-7                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-8                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-9                        78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-10                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-11                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-12                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-13                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-14                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-15                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-16                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-17                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-18                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-19                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-20                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-21                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-22                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-23                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-24                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-25                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-26                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-27                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-28                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-29                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-30                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-31                       78,671,360\n",
      "│    │    └─PhiDecoderLayer: 3-32                       78,671,360\n",
      "│    └─LayerNorm: 2-4                                   5,120\n",
      "├─Linear: 1-2                                           131,123,200\n",
      "================================================================================\n",
      "Total params: 2,779,683,840\n",
      "Trainable params: 2,779,683,840\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "SparseAutoencoder                        [1, 100, 2560]            --\n",
      "├─Sequential: 1-1                        [1, 100, 100000]          --\n",
      "│    └─Linear: 2-1                       [1, 100, 100000]          256,100,000\n",
      "│    └─ReLU: 2-2                         [1, 100, 100000]          --\n",
      "├─Linear: 1-2                            [1, 100, 2560]            256,002,560\n",
      "==========================================================================================\n",
      "Total params: 512,102,560\n",
      "Trainable params: 512,102,560\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 512.10\n",
      "==========================================================================================\n",
      "Input size (MB): 10.24\n",
      "Forward/backward pass size (MB): 82.05\n",
      "Params size (MB): 2048.41\n",
      "Estimated Total Size (MB): 2140.70\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "print(summary(phi, input_shape=(5, 100)))\n",
    "\n",
    "print(summary(sae, input_data=next(all_activations(split='train'))[1][0:1]))\n",
    "\n",
    "# sae2 = sae.half()\n",
    "# print(summary(sae2, input_data=next(all_activations(split='train'))[1][0:1].half()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e4afb97-0777-4be6-9718-2fe591b49303",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_train_more = False\n",
    "if should_train_more:\n",
    "    train(sae, start_block=500, num_tokens=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be28aa-69c9-4e73-9187-a2990a7e6170",
   "metadata": {},
   "source": [
    "## Now let's see how our accuracy and sparsity do compared to a random Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c42a210-f31a-42b3-aa3a-134c2a692c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae2 = SparseAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73a23cb8-f90d-4e6e-81e0-a6e8a376d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, activations = next(all_activations('test', minibatch_size=5, block_size=100, start_block=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7af6540b-cba3-4c29-bdf4-4500f9f9f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on minibatch including:\n",
      "---\n",
      " and such conditions. Now let\n",
      "us suppose a teacher of genius to obtain the post. He not only teaches\n",
      "admirably, but he institutes school gardens for the children; he takes\n",
      "long walks with the boys, and gives them the rudiments of geology. He\n",
      "is in himself an uplifting moral influence, and introduces the children\n",
      "into a whole new world of idea and of feeling. The parents are pleased.\n",
      "I will not say that they are grateful; but they\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(f'Testing on minibatch including:\\n---\\n{tokenizer.decode(tokens[0])}\\n---\\n')\n",
    "    trained_decoded, trained_encoded = sae(activations)    \n",
    "    untrained_decoded, untrained_encoded  = sae2(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced93995-b4c5-4497-99f1-a0701a67c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model:\n",
      "\t- Accuracy loss: 6043.6\n",
      "\t- Sparsity loss: 87.7\n",
      "\t- Total loss: 6131.2\n",
      "\n",
      "Trained model:\n",
      "\t- Accuracy loss: 358.1\n",
      "\t- Sparsity loss: 121.2\n",
      "\t- Total loss: 479.3\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trained_total, trained_accuracy, trained_sparsity = calculate_loss(sae, trained_decoded, activations, trained_encoded)\n",
    "    untrained_total, untrained_accuracy, untrained_sparsity = calculate_loss(sae2, untrained_decoded, activations, trained_encoded)\n",
    "\n",
    "print('Untrained model:')\n",
    "print(f'\\t- Accuracy loss: {untrained_accuracy / 2500:.1f}')\n",
    "print(f'\\t- Sparsity loss: {untrained_sparsity / 2500:.1f}')\n",
    "print(f'\\t- Total loss: {untrained_total / 2500:.1f}')\n",
    "print('')\n",
    "print('Trained model:')\n",
    "print(f'\\t- Accuracy loss: {trained_accuracy / 2500:.1f}')\n",
    "print(f'\\t- Sparsity loss: {trained_sparsity / 2500:.1f}')\n",
    "print(f'\\t- Total loss: {trained_total / 2500:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80446f8b-bd81-4ddf-9022-2af9a09ef415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
