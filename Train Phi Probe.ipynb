{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08198559-0546-4a9c-b616-9ce2842fd1f7",
   "metadata": {},
   "source": [
    "## Load Common Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecefaac6-9f6f-4588-b8df-6b2f4959fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post304)\n",
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-08-03 16:21:54.282196: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-03 16:21:54.319653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84df3d4460d84a0abae702ceb44f3901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "%run Common\\ Code.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499c76c-2591-453a-a9bc-e8b89c2d65ea",
   "metadata": {},
   "source": [
    "## Now define our autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f93598-167b-449e-9573-90e038d86cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparseAutoencoder is defined in 'Common Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871ec152-cd46-43f4-b4f2-a7e0074439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('sae.pt').exists():\n",
    "    sae = torch.load('sae.pt').to(device)\n",
    "    is_trained = True\n",
    "else:\n",
    "    sae = SparseAutoencoder()\n",
    "    is_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395fa780-5d92-4742-8978-9fcb9d77430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def calculate_loss(sae_model, prediction, target, feature_activations, lamb=5):\n",
    "    weight_norms = torch.norm(sae_model.decoder.weight, dim=0, p=2).view(-1)\n",
    "    feature_sizes = torch.abs(feature_activations)\n",
    "    sparsity_loss = lamb * torch.sum(weight_norms * feature_sizes)\n",
    "\n",
    "    prediction_loss = F.mse_loss(prediction, target, reduction='sum')\n",
    "\n",
    "    total_loss = prediction_loss + sparsity_loss\n",
    "    \n",
    "    return total_loss, prediction_loss, sparsity_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d944680f-4a0f-470b-b2a3-798cc0f3e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15655829504 7822376960 7616183296 206193664\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t, r, a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24c23c-418a-4b12-acdf-bb8117887a64",
   "metadata": {},
   "source": [
    "## Train our autoencoder on 1M tokens' worth of activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1048f3ee-14c2-490b-b308-348f92ca2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 25000; Loss: 21140.35; Sparsity-specific loss: 10790.55:   2%|▏         | 49/2000 [00:57<38:25,  1.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 25000 tokens\n",
      "\t - Training data: loss is 21140.35; sparsity loss is 10790.55\n",
      "\t - Eval data: loss is 10860.99; sparsity loss is 7113.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 50000; Loss: 15341.17; Sparsity-specific loss: 8403.92:   5%|▍         | 99/2000 [01:57<37:35,  1.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 50000 tokens\n",
      "\t - Training data: loss is 15341.17; sparsity loss is 8403.92\n",
      "\t - Eval data: loss is 8358.58; sparsity loss is 4661.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokens seen: 50000; Loss: 15341.17; Sparsity-specific loss: 8403.92:   5%|▍         | 99/2000 [02:00<38:27,  1.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(sae, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msae.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_trained:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     is_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(sae, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msae.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(sae_model, num_tokens, minibatch_size, block_size, loss_history, adam_beta1, adam_beta2, lr, eval_tokens, show_eval_token_interval, start_block)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m - Training data: loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; sparsity loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_sparsity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m - Eval data: loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; sparsity loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_sparsity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)            \n\u001b[0;32m---> 51\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msae.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:665\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 665\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/storage.py:121\u001b[0m, in \u001b[0;36m_StorageBase.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_eval_loss(sae_model, minibatches, tokens_per_minibatch):\n",
    "    losses = []\n",
    "    sparsities = []\n",
    "    accuracies = []\n",
    "    for tokens, activations in minibatches:\n",
    "        decoded, encoded = sae_model(activations)\n",
    "        loss, accuracy, sparsity = calculate_loss(sae_model, decoded, activations, encoded)\n",
    "        losses.append(loss.item() / tokens_per_minibatch)\n",
    "        accuracies.append(accuracy.item() / tokens_per_minibatch)        \n",
    "        sparsities.append(sparsity.item() / tokens_per_minibatch)        \n",
    "    return sum(losses) / len(losses), sum(accuracies) / len(accuracies), sum(sparsities) / len(sparsities)\n",
    "\n",
    "def train(sae_model, num_tokens=1000000, minibatch_size=5, block_size=100, loss_history=100, adam_beta1=0.9, adam_beta2=0.999, lr=5E-5, eval_tokens=1000, show_eval_token_interval=25000, start_block=0):            \n",
    "    optimizer = torch.optim.AdamW(sae_model.parameters(), lr=lr, betas=(adam_beta1, adam_beta2))\n",
    "    tokens_per_minibatch = minibatch_size * block_size\n",
    "    num_minibatches = num_tokens // tokens_per_minibatch\n",
    "    eval_minibatches = eval_tokens // tokens_per_minibatch\n",
    "    losses = []\n",
    "    sparsities = []\n",
    "    activations_gen = PhiProbeCommons.all_activations('train', minibatch_size=minibatch_size, block_size=block_size + start_block)\n",
    "    test_activations_gen = PhiProbeCommons.all_activations('test', minibatch_size=minibatch_size, block_size=block_size, start_block=1000+start_block)    \n",
    "    \n",
    "    training_data = islice(activations_gen, num_minibatches)         \n",
    "    show_eval_minibatch_interval = show_eval_token_interval // tokens_per_minibatch\n",
    "\n",
    "    pbar = tqdm(training_data, total=num_minibatches, smoothing=0)\n",
    "    for idx, (tokens, activations) in enumerate(pbar):        \n",
    "        decoded, encoded = sae_model(activations)        \n",
    "        loss, accuracy, sparsity = calculate_loss(sae_model, decoded, activations, encoded)        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        losses.append(loss.item() / tokens_per_minibatch)\n",
    "        sparsities.append(sparsity.item() / tokens_per_minibatch)\n",
    "        if len(losses) > loss_history:\n",
    "            losses = losses[1:]\n",
    "            sparsities = sparsities[1:]\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        avg_sparsity = sum(sparsities) / len(sparsities)\n",
    "        tokens_seen = (idx + 1) * tokens_per_minibatch\n",
    "        pbar.set_description(f'Tokens seen: {tokens_seen}; Loss: {avg_loss:.2f}; Sparsity-specific loss: {avg_sparsity:.2f}')\n",
    "        if (idx + 1) % show_eval_minibatch_interval == 0:\n",
    "            minibatches = islice(test_activations_gen, eval_minibatches)\n",
    "            eval_loss, _, eval_sparsity = get_eval_loss(sae_model, minibatches, tokens_per_minibatch)\n",
    "            print(f'Seen {tokens_seen} tokens')\n",
    "            print(f'\\t - Training data: loss is {avg_loss:.2f}; sparsity loss is {avg_sparsity:.2f}')\n",
    "            print(f'\\t - Eval data: loss is {eval_loss:.2f}; sparsity loss is {eval_sparsity:.2f}')            \n",
    "            torch.save(sae, 'sae.pt')\n",
    "\n",
    "if not is_trained:\n",
    "    train(sae)\n",
    "    is_trained = True\n",
    "    torch.save(sae, 'sae.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be28aa-69c9-4e73-9187-a2990a7e6170",
   "metadata": {},
   "source": [
    "## Now let's see how our accuracy and sparsity do compared to a random Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c42a210-f31a-42b3-aa3a-134c2a692c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae2 = SparseAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a23cb8-f90d-4e6e-81e0-a6e8a376d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, activations = next(PhiProbeCommons.all_activations('test', minibatch_size=5, block_size=100, start_block=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af6540b-cba3-4c29-bdf4-4500f9f9f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on minibatch including:\n",
      "---\n",
      " and such conditions. Now let\n",
      "us suppose a teacher of genius to obtain the post. He not only teaches\n",
      "admirably, but he institutes school gardens for the children; he takes\n",
      "long walks with the boys, and gives them the rudiments of geology. He\n",
      "is in himself an uplifting moral influence, and introduces the children\n",
      "into a whole new world of idea and of feeling. The parents are pleased.\n",
      "I will not say that they are grateful; but they\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(f'Testing on minibatch including:\\n---\\n{PhiProbeCommons.tokenizer.decode(tokens[0])}\\n---\\n')\n",
    "    trained_decoded, trained_encoded = sae(activations)    \n",
    "    untrained_decoded, untrained_encoded  = sae2(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced93995-b4c5-4497-99f1-a0701a67c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model:\n",
      "\t- Accuracy loss: 6086.3\n",
      "\t- Sparsity loss: 902.1\n",
      "\t- Total loss: 6988.4\n",
      "\n",
      "Trained model:\n",
      "\t- Accuracy loss: 673.8\n",
      "\t- Sparsity loss: 871.9\n",
      "\t- Total loss: 1545.7\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trained_total, trained_accuracy, trained_sparsity = calculate_loss(sae, trained_decoded, activations, trained_encoded)\n",
    "    untrained_total, untrained_accuracy, untrained_sparsity = calculate_loss(sae2, untrained_decoded, activations, trained_encoded)\n",
    "\n",
    "print('Untrained model:')\n",
    "print(f'\\t- Accuracy loss: {untrained_accuracy / 2500:.1f}')\n",
    "print(f'\\t- Sparsity loss: {untrained_sparsity / 2500:.1f}')\n",
    "print(f'\\t- Total loss: {untrained_total / 2500:.1f}')\n",
    "print('')\n",
    "print('Trained model:')\n",
    "print(f'\\t- Accuracy loss: {trained_accuracy / 2500:.1f}')\n",
    "print(f'\\t- Sparsity loss: {trained_sparsity / 2500:.1f}')\n",
    "print(f'\\t- Total loss: {trained_total / 2500:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80446f8b-bd81-4ddf-9022-2af9a09ef415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
