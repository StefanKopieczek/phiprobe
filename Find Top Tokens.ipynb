{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bd94f2-c483-472c-8c89-32513b5d6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post304)\n",
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-08-04 12:57:15.700820: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-04 12:57:15.738181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df570594cd284565a4348ff848b92324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "%run Common\\ Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa76723-aaad-4306-83d0-3d05695331bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopTokenList:\n",
    "    def __init__(self, max_size):\n",
    "        self._members = []\n",
    "        self._max_size = max_size\n",
    "        self._worst_score = None\n",
    "\n",
    "    def maybe_add(self, tokens, activations):\n",
    "        for token_idx, activation in enumerate(activations):\n",
    "            if self._worst_score is not None and activation > self._worst_score:\n",
    "                self._members.append((tokens, token_idx, activation))\n",
    "                self._members.sort(key = lambda x: x[2], reverse=True)\n",
    "        \n",
    "            if len(self) > self._max_size:\n",
    "                self._drop_worst()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._members)\n",
    "\n",
    "    def _drop_worst(self):        \n",
    "        self._members = self._members[:self._max_size]\n",
    "\n",
    "    def get_all(self):\n",
    "        return self._members[:]\n",
    "\n",
    "    def get_worst_score(self):\n",
    "        return self._worst_score\n",
    "\n",
    "    def get_best_score(self):\n",
    "        if self._members:\n",
    "            return self._members[0][2]\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "class TopTokens:\n",
    "    def __init__(self, num_top_tokens=20):\n",
    "        self.top_tokens = [TopTokenList(num_top_tokens) for _ in range(100_000)]\n",
    "\n",
    "    def incorporate(self, tokens_minibatch, sae_activations_minibatch):\n",
    "        \"\"\"\n",
    "        Expects two tensors:\n",
    "         - tokens: dimension (MB, BS) where MB is (any) minibatch size and BS is (any) block size,\n",
    "                   representing a minibatch of token strings given to an LLM.\n",
    "         - sae_activations: dimension (MB, 100_000) where MB is as above.\n",
    "                            Represents the activation of each neuron of the SAE hidden layer\n",
    "                            when inspecting an LLM presented with the given tokens.\n",
    "        Updates the top_tokens for each SAE neuron according to their activations.\n",
    "        \"\"\"\n",
    "        for tokens, sae_activations in zip(tokens_minibatch, sae_activations_minibatch.permute(0, 2, 1)):\n",
    "            for neuron_idx, top_token_list in enumerate(self.top_tokens):\n",
    "                top_token_list.maybe_add(tokens, sae_activations[neuron_idx])\n",
    "\n",
    "    def display(self):       \n",
    "        clear_output(wait=True)\n",
    "        lines = ['<h3>Top Tokens</h3>']\n",
    "        for idx in chain(range(5), range(99_995, 100_000)):            \n",
    "            if self.top_tokens[idx].get_worst_score() is None:\n",
    "                lines.append(f'<strong>Neuron {idx}:</strong> awaiting tokens<br>')\n",
    "            else:\n",
    "                lines.append(f'<strong>Neuron {idx}</strong>: {len(self.top_tokens[idx])} tokens (range {self.top_tokens[idx].get_worst_score():.2f} - {self.top_tokens[idx].get_best_score():.2f}<br>')\n",
    "        html_custom = ''.join(lines)\n",
    "        display(HTML(html_custom))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01a750c9-8508-468b-a87e-ea6853194b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sae_activations():\n",
    "    sae = PhiProbeCommons.sae()\n",
    "    for tokens, activations in PhiProbeCommons.all_activations(split='test'):\n",
    "        _, sae_activations = sae(activations)\n",
    "        yield tokens, sae_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "294a3ed9-234e-4514-8bd5-a4b22fe4d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Top Tokens</h3><strong>Neuron 0:</strong> awaiting tokens<br><strong>Neuron 1:</strong> awaiting tokens<br><strong>Neuron 2:</strong> awaiting tokens<br><strong>Neuron 3:</strong> awaiting tokens<br><strong>Neuron 4:</strong> awaiting tokens<br><strong>Neuron 99995:</strong> awaiting tokens<br><strong>Neuron 99996:</strong> awaiting tokens<br><strong>Neuron 99997:</strong> awaiting tokens<br><strong>Neuron 99998:</strong> awaiting tokens<br><strong>Neuron 99999:</strong> awaiting tokens<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100, 100000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tokens, sae_activations \u001b[38;5;129;01min\u001b[39;00m all_sae_activations():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sae_activations\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtop_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincorporate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     top_tokens\u001b[38;5;241m.\u001b[39mdisplay()\n",
      "Cell \u001b[0;32mIn[25], line 53\u001b[0m, in \u001b[0;36mTopTokens.incorporate\u001b[0;34m(self, tokens_minibatch, sae_activations_minibatch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tokens, sae_activations \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tokens_minibatch, sae_activations_minibatch\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neuron_idx, top_token_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_tokens):\n\u001b[0;32m---> 53\u001b[0m         \u001b[43mtop_token_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneuron_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m, in \u001b[0;36mTopTokenList.maybe_add\u001b[0;34m(self, tokens, activations)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, activations):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token_idx, activation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worst_score \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m activation \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worst_score:\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members\u001b[38;5;241m.\u001b[39mappend((tokens, token_idx, activation))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:940\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    932\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[0;32m--> 940\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "top_tokens = TopTokens()\n",
    "for tokens, sae_activations in all_sae_activations():\n",
    "    print(sae_activations.shape)\n",
    "    top_tokens.incorporate(tokens, sae_activations)\n",
    "    top_tokens.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea2f27-2e68-4c26-8197-8cc088bd22fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
